# A 'job server' which actually runs the requests.  At the moment this is
# simply a proof of concept.  It runs one job at a time and has no 
# provisions for supporting multiple job managers or multiple in flight jobs.
# This job-server will try to run jobs which haven't been started before, but 
# will not retry jobs which have previously run and failed (for *any* reason)

import os
import subprocess
import shutil
import sys
import time
import datetime
import json


# For simplicity, we're going to use django's orm interface for accessing the
# database.  The avoids having the (autogenerated) db field names hard coded.
import django
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "service.settings")
# Note: PYTHONPATH needs to point at lc-service/service/
django.setup()

from api import models

# open connection to log
# claim active job manager role (others may keep running)

# A generator routine which enumerates the set of pending jobs to be run
def pending_jobs():
    messages = models.LogMessage.objects.all()
    jobs = dict()
    for message in messages:
        payload = message.payload
        data = json.loads(payload)
        action = data["action"]
        if action == "job_start":
            assert not message.request.id in jobs
            jobs[message.request.id] = True
        elif action in ["job_started", "job_finished", "job_stop"]:
            assert message.request.id in jobs
            jobs[message.request.id] = False
        elif action in ["job_finished"]:
            assert message.request.id in jobs
            assert not jobs[message.request.id]


    for key, value in jobs.items():
        # A true value implies this job hasn't yet run...
        if value:
            # TODO: shed if too old or load too high
            # TODO: error handling
            request = models.Request.objects.get(pk=key)
            yield request

def add_message_to_log(message_dict, request):
    message_json = json.dumps(message_dict)
    message = models.LogMessage.objects.create(request=request, 
                                               datetime=datetime.datetime.now(),
                                               payload=message_json)
    print "logged: " + str(message)


def run_job(request, jobtype):
    print "Running job: " + jobtype + " " +str(request)
    
    # Before actually starting the job, record the fact we're about to do so.
    # If we see this job in the log after a restart, we don't want it to 
    # rerun (since it may have caused us to crash in the first place)
    message_dict = {"action": "job_started"}
    add_message_to_log(message_dict, request)

    # TODO: async using popen and observe jobs
    # TODO: logging, log files?
    if "echo" == jobtype:
        print "echo: " + str(request)
    elif "clang-modernize" == jobtype:
        # TODO: add various other interesting options
        print "job type unsupported"
        #cmd = "python run-clang-modernize-job.py %s" % (repo)
        # TODO: set cwd
        #subprocess.call(cmd)
        pass
    elif "build" == jobtype:
        repo = request.repo
        # TODO: add various other interesting options
        cmd = "python run-build-only-job.py %s" % (repo)
        # TODO: set cwd
        # TODO: remove shell=True via explicit command path
        subprocess.call(cmd, shell=True)#
        pass
    elif "clang-tidy" == jobtype:
        print "job type unsupported"
        pass
    elif "clang-format" == jobtype:
        #cmd = "python run-clang-modernize-job.py %s" % (repo)
        # TODO: set cwd
        #subprocess.call(cmd)
        print "job type unsupported"
        pass
    else:
        print "error: illegal job type!"

    # Record the fact the job finished (normally)
    # TODO: add 'job_aborted'
    message_dict = {"action": "job_finished"}
    add_message_to_log(message_dict, request)


print "Entering job-server loop"
started = datetime.datetime.now()
# job server is externally restarted periodically
while datetime.datetime.now() < started + datetime.timedelta(minutes=120):
    print "Checking for work @" +str(datetime.datetime.now())

    # pull out any open requests
    # - use a last processed job ID
    # - possibly a pair: max completed, last considered
    # agressively shed load as required
    # TDOO: take into consideration load on the system
    

    # Batch process pending job requests - this is currently strictly FIFO,
    # but more complicated policies can and should be applied.
    for request in pending_jobs():
        print "pending: " + str(request)
        
        # Note: Need to rate limit the work somehow, for now, this is 
        # handled by having a single blocking call per job
    
        run_job(request, "build")
        

    #TODO: implement various job manager commands
    # e.g. restart, stop

    # sleep for X seconds, then check for new jobs
    # TODO: implement a reasonable backoff policy here, or does
    # it actually matter?
    time.sleep(5);

# TODO: When we get around to implementing a parallelization 
# scheme, implement graceful shutdown for jobs running at timeout.
